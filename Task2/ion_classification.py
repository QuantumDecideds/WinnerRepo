# -*- coding: utf-8 -*-
"""ion_classification.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1IP8w6KboCxWnPvPmelDldNwpichZkveo
"""

import os
import torch
import pandas as pd
import csv
from typing import Optional

import numpy as np
from PIL import Image
from torch.utils.data import Dataset
from torch.utils.data import DataLoader
from torch.nn import functional as F
import albumentations as A
import pytorch_lightning as pl

from torchvision import datasets
import torchvision
from torchvision.transforms import ToTensor
from torchvision.io import read_image

import numpy as np
from skimage.io import imread, imsave
import qubovert as qv
import qubovert.utils
import pickle as pkl
from matplotlib import pyplot as plt

MyTransform = A.Compose(
    [
        #A.Crop(x_min=0, y_min=0, x_max=55, y_max=40),
        A.Crop(x_min=0, y_min=40, x_max=55, y_max=80),
        A.Crop(x_min=0, y_min=80, x_max=55, y_max=120),
        A.Crop(x_min=0, y_min=120, x_max=55, y_max=160),
    ]
)

for i in range(1, len(os.listdir('Data/train_data'))):
    #if os.path.isfile(os.path.join('Data/train_data', f)):
    #print(os.listdir('Data/train_data'))
        f = os.listdir('Data/train_data')[i]
        plate = imread(os.path.abspath("Data/train_data/" + f))
        image = np.array([plate[:40, :, :], plate[40:80, :, :], plate[80:120, :, :], plate[120:, :, :]])
        print(os.path.abspath("Data/train_data_cropped/" + f) + '___0')
        imsave(os.path.abspath("Data/train_data_cropped/" + f) + '___0', image[0])
        imsave(os.path.abspath("Data/train_data_cropped/" + f) + '___1', image[1])
        imsave(os.path.abspath("Data/train_data_cropped/" + f) + '___2', image[2])
        imsave(os.path.abspath("Data/train_data_cropped/" + f) + '___3', image[3])

from google.colab import drive
drive.mount('/content/drive')

class CustomDataset(Dataset):
    def __init__(self, data_dir, split, transform=None):
        self.data_dir = data_dir
        self.split = split
        self.transform = transform

        super(CustomDataset, self).__init__()
        ## list of tuples: (img_path, label)
        self._items = []

        ## will use it later for augmentations
        self._transform = transform

        split_dir = os.path.join(self.data_dir, self.split + '_cropped')
        file_list = [os.path.join(split_dir, file) for file in os.listdir(split_dir) if os.path.isfile(os.path.join(split_dir, file))]
        labels_file = os.path.join(self.data_dir, self.split + '.csv')
        flabels = []
        labels = []
        with open(labels_file) as csvfile:
            flabels = csv.reader(csvfile, delimiter=';')
            for row in flabels:
                labels.append(row)
        del labels[0]
        for i in range(len(file_list)):
            self._items.append((file_list[i], labels[i // 4][i % 4]))

    def __len__(self):
        return len(self._items)

    def __getitem__(self, index):
        img_path, label = self._items[index]

        ## read image
        image = Image.open(img_path).convert("RGB")
        image = np.array(image).astype(np.float32)

        ## augmentation
        if self._transform:
            image = self._transform(image=image)["image"]

        ## to Tensor
        x = torch.from_numpy(image).permute(2, 0, 1)

        return x, label

train_dataset = CustomDataset(data_dir='Data', split='train_data', transform=None)
#test_dataset = CustomDataset(data_dir='Data', split='test_data', transform=None)

dl_train = DataLoader(train_dataset, batch_size=1, shuffle=True, num_workers=os.cpu_count())
#dl_val = DataLoader(test_dataset, batch_size=1, shuffle=False, num_workers=os.cpu_count())

class Model(torch.nn.Sequential):
    def __init__(self):
        super().__init__()
        self.flatten = torch.nn.Flatten(start_dim=1, end_dim=-1)
        self.l1 = torch.nn.Linear(6720, 16)
        self.a1 = torch.nn.ReLU()
        self.l2 = torch.nn.Linear(16, 1)

class TrainingModule(pl.LightningModule):
    def __init__(self):
        super().__init__()
        self.model = Model()
        self.train_loss = []

    def training_step(self, batch, batch_idx):
        x, y_gt = batch
        y_pr = self.model(x)
        int_y_gt = []
        for i in y_gt:
            int_y_gt.append(float(i[0]))
        loss = F.cross_entropy(y_pr, torch.tensor(int_y_gt).long())
        self.train_loss.append(loss.detach())
        return loss

    def configure_optimizers(self):
        return torch.optim.SGD(self.parameters(), lr=0.001)

training_module = TrainingModule()

trainer = pl.Trainer(accelerator="cpu", devices=1, max_epochs=3)

print("MODULE: ", training_module, " DL_TRAIN: ", dl_train)
trainer.fit(training_module, dl_train)

imgs_names = os.listdir('Data/train_data_cropped')
imgs = []
for i in range(len(imgs_names)):
    imgs.append(imread(imgs_names))

R_mean = np.zeroes(len(imgs))
G_mean = np.zeroes(len(imgs))
B_mean = np.zeroes(len(imgs))
for i in range(len(imgs)):
    for k in range(imgs[i].shape[0]):
        for j in range(imgs[i].shape[1]):
            R_mean[i] += (1. / (imgs[i].shape[0] * imgs[i].shape[1])) * imgs[i, k, j, 0]
            G_mean[i] += (1. / (imgs[i].shape[0] * imgs[i].shape[1])) * imgs[i, k, j, 1]
            B_mean[i] += (1. / (imgs[i].shape[0] * imgs[i].shape[1])) * imgs[i, k, j, 2]

image = np.zeros((4, 6888), dtype='int')
for i in range(4):
    image[i] = np.ndarray.flatten(image1[i])

N_weights = image[0].shape[0]
y = np.array([1, 1, 1, 1])

discr_left = 3
discr_right = 2
N_discr = discr_left + discr_right + 1

W = {(i, j): qv.QUBO.create_var('x%d%d'% (i, j)) for i in range(N_weights) for j in range(N_discr)}

model = 0
# print(image[1][2])

for i in range (4):
    summ = 0
    for j in range(image[i].shape[0]):
        w = 0
        for k in range(N_discr):
            w += 2  (k - discr_left + 1) * W[(j, k)]
        summ += w * image[i][j]
    summ -= y[i]
    model += summ ** 2


#offset = model[()]
#model[()] = 0
#fileName = 'Q.pkl'
#fileObject = open(fileName, 'wb')

#pkl.dump(arrayInput, fileObject)
#fileObject.close()

solution_SA = qv.sim.anneal_qubo(model, num_anneals=1)
#np_model = qubovert.utils.qubo_to_matrix(model, symmetric=True, array=True)

# W = np.array((4, image[0].shape[0]), dtype='float32')

print(solution_SA.res.best.value)

state = solution_SA.res.best.state

plate2 = imread('ion_pic2.png')
print(np.shape(plate2))
image2 = np.array([plate2[:41, :, :], plate2[41:82, :, :], plate2[82:123, :, :], plate2[123:, :, :]])

image3 = np.zeros((4,6888), dtype='int')


for i in range(4):
    image3[i] = np.ndarray.flatten(image2[i])

# for i in image2:
#     i = np.ndarray.flatten(i)

summ = np.zeros(4)
for i in range(4):
    for j in range(image2[i].shape[0]):
        w = 0
        for k in range(N_discr):
            w += 2 ** (k - discr_left + 1) * state[(j, k)]
        summ[i] += w * image2[i, j]

print(summ)

